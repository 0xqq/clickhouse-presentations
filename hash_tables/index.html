<!DOCTYPE html>
<html lang="en">
<head>
    <title>Как устроены хэш-таблицы в ClickHouse</title>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="shower/themes/ribbon/styles/screen-16x10.css">
    
    <style type="text/css">
         span { padding: 10px 10px; background: rgba(255, 255, 255, 0.75); }
         code { display: block; background-color: #EEE; white-space: pre; }
         h2 { line-height: 1.5 !important; padding-bottom: 30px; }
    </style>
</head>
<body class="shower list">
    <header class="caption">
        <h1>Как устроены хэш-таблицы в ClickHouse</h1>
    </header>

    <section class="slide" id="cover" style="background: url('pictures/xor.png') no-repeat center center; background-size: 100%">
        <h1 style="margin-top: 200px;"><span>Как устроены хэш-таблицы</span><br/><span>в ClickHouse</span></h1>
    </section>

    <section class="slide">
        <h2>Обо мне</h2>
        <p>Алексей, разработчик ClickHouse.</p>
        <p>С 2008 занимался движком обработки данных в Яндекс.Метрике.</p>
    </section>

<section class="slide">
<h2>Где нужны хорошие хэш-таблицы</h2>

<p>GROUP BY<br>
SELECT DISTINCT<br>
IN, JOIN</p>

<p><br>А также:<br>
— uniqExact, uniq;<br>
— arrayEnumerateUniq;<br>
— LIMIT BY.</p>
</section>

<section class="slide">
<h2>Что такое хэш-таблица</h2>
</section>

<section class="slide">
<h2>Чем отличаются хэш-таблицы<br>от lookup таблиц?</h2>

<p>1. Хэширование.</p>
<p>2. Разрешение коллизий.</p>
<p>3. Ресайзы.</p>
<p>&nbsp;</p>
<p>Все пункты не являются обязательными.</p>
<p>Пример: direct mapped cache.</p>
</section>

<section class="slide">
<h2>Хэширование</h2>

<div style="float: right; text-align: right;">
<img src="pictures/power.png" style="margin-bottom: -30px;" />
<br><span style="padding-right: 10px; font-size: 10px;">xkcd.com</span>
</div>

<p>Магический приём, который пронизывает<br>всё software engineering &amp; computer science.</p>
<p>Используется повсеместно.</p>
<p>Алгоритмы поиска, машинное обучение,<br>распределённые системы, сжатие данных,<br>sketching структуры данных...</p>
</section>

<section class="slide">
<h2>Ошибки при выборе хэш-функции</h2>

<p>1. Использование тривиальной хэш-функции</p>

<code>hash(x) = x
</code>

<p>
Так сделано в реализации стандартной библиотеки (std::hash)<br>в libstdc++ и в libc++ для int-ов.</p>
</section>

<section class="slide">
<h2>Почему тривиальная хэш-функция<br>— это плохо.</h2>

<p>Пример: посчитаем, сколько раз каждый пользователь был в интернете.</p>
<p>На входе — массив yandexuid.<br>yandexuid — UInt64</p>

<code>for (const auto &amp; key : data)
    ++map[key];
</code>

<p>
Всего 100 000 000 посещений, в них 17 630 976 разных yandexuid.<br>
value_type — 16 байт, оперативки примерно 260 MB<br>— не помещается в LL кэш.</p>
</section>

<section class="slide">
<p>
Что такое yandexuid: concat(rand, timestamp).<br>
Младшие биты — unix timestamp с точностью до секунд.</p>

<img src="pictures/traffic.png" style="height:70%"/>

<code>
SELECT toHour(EventTime) * 60 + toMinute(EventTime) AS k, count() AS c FROM hits_all WHERE EventDate >= today() - 365 GROUP BY k ORDER BY k INTO OUTFILE 'minutes.tsv' FORMAT TabSeparated
</code>

1440 rows in set. Elapsed: 800.580 sec. Processed 4.33 trillion rows, 26.00 TB (5.41 billion rows/s., 32.48 GB/s.)
</section>

<section class="slide">
<h2>Насколько тривиальная хэш-функция хуже</h2>

std::unordered_set
— разницы в производительности нет (10.319 vs 10.279 сек)

google::dense_hash_map
— разница в производительности: 3.156 vs 81.86 сек — в 26 раз

ClickHouse HashMap
— разница в производительности: 2.527 vs 10.264 сек — в 4 раза
</section>

<section class="slide">
<h2>2. Ошибки при комбинировании хэш-функций</h2>

hash(x, y) = hash(x) ^ hash(y)
— ужасно, так делать нельзя

hash(x, y) = hash(hash(x) ^ y)
— можно так, но зачастую можно лучше
</section>

<section class="slide">
<h2>3. Использование для типов фиксированной длины хэш-функции для строк.</h2>

Пример:
<code>
hash(int x) = CityHash64(reinterpret_cast&lt;const char *&gt;(&amp;x), sizeof(x))
</code>
— очень плохо.

— хэш-функции для строк как правило не инлайнятся;
— они содержат много бранчей — представляют собой вариации на тему duff device для fast path цикла и обработки хвостиков,
  всё это не нужно, если хэшируем типы фиксированной длины.
</section>

<section class="slide">
<h2>Почему плохо</h2>

HashMap в ClickHouse:
— хорошая хэш-функция: 2.439 сек.
— ошибочно используем CityHash64 для UInt64: 3.347 сек.
— используем murmur finalizer: 2.722 сек.
— тривиальная хэш-функция: 9.721 сек.

std::unordered_map:
— хорошая хэш-функция: 10.097 сек.
— ошибочно используем CityHash64 для UInt64: 11.040 сек.

(производительность скрадывается зависимыми кэш-промахами)

https://github.com/yandex/ClickHouse/blob/master/dbms/src/Common/tests/integer_hash_tables_and_hashes.cpp
</section>

<section class="slide">
<h2>4. Интерференция хэш-функций</h2>

Для прямо или косвенно связанных друг с другом структур данных используйте разные хэш-функции.
Пример: для шардирования данных и для хэш-таблиц при обработке этих данных.

Приводит к замедлению в разы или к полному залипанию!

Иногда выбор нескольких хэш-функций из одного семейства — недостаточно хорошее решение.
Пример: <code>hash(x, seed) = hash(x ^ seed)</code> — зачастую недостаточно хорошо из-за того, что часть операций hash коммутирует с xor.
</section>

<section class="slide">
<h2>5. Использование устаревших медленных хэш-функций низкого качества</h2>

Пример: в libstdc++ из gcc 7 используется FNV1a для строк.
Эта хэш-функция содержит цикл по байтам, может работать не медленно только для коротких строк,
но для коротких строк слишком низкое качество.
</section>

<section class="slide">
<h2>5. Использование устаревших медленных хэш-функций низкого качества</h2>

Пример: 

PageCharset — короткие повторяющиеся строки (windows-1251, utf-8)
Делаем 5 млн. вставок.
— FNV1a: 76 409 407 inserts/sec.
— CityHash64: 94 725 900 inserts/sec.
— хэш-функция из ClickHouse: 112 791 109 insets/sec.

URL — много разных строк ~60 байт
— FNV1a: 10 108 171 inserts/sec.
— CityHash64: 11 337 682 inserts/sec.
— хэш-функция из ClickHouse: 13 637 320 insets/sec.

https://github.com/yandex/ClickHouse/blob/master/dbms/src/Interpreters/tests/hash_map_string_3.cpp
</section>

<section class="slide">
<h2>6. Использование криптографических хэш-функций без необходимости</h2>

Иногда не ошибка, если надо избежать algorithmic complexity attack.
В этом случае используйте SipHash. Не используйте MD5, SHA1,2,3.

Но добиться этого иногда можно и другими способами (выбор случайной хэш-функции из семейства),
правда это работает не всегда.
</section>

<section class="slide">
<h2>6. Использование криптографических хэш-функций без необходимости</h2>

Пример:

URL:
CityHash64: 3755.84 MB/sec.
SipHash: 1237.51 MB/sec.
MD5: 361.86 MB/sec.

SearchPhrase:
CityHash64: 822.56 MB/sec.
SipHash: 183.35 MB/sec.
MD5: 30.87 MB/sec.

https://github.com/yandex/ClickHouse/blob/master/dbms/src/Common/tests/hashes_test.cpp
</section>

<section class="slide">
<h2>Оценка качества некриптографической хэш-функции</h2>

Пример: SMHasher,

Avalanche, Bit Independence Criteria

Картинка
</section>

<section class="slide">
<h2>Недостаток критерия Avalanche</h2>

Для разных алгоритмов имеют смысл разные критерии качества хэш-функций.
Хэш-функция может быть качественной для linear probing open addressing hash table,
но не качественной для HyperLogLog.
</section>

<section class="slide">
<h2>Примеры хэш-функций для int-ов</h2>
</section>

<section class="slide">
<h2>1. Murmur finalizer</h2>
<code>
inline UInt64 intHash64(UInt64 x)
{
    x ^= x >> 33;
    x *= 0xff51afd7ed558ccdULL;
    x ^= x >> 33;
    x *= 0xc4ceb9fe1a85ec53ULL;
    x ^= x >> 33;

    return x;
}
</code>

2.5 "раунда", состоящих из xor-shift и умножения.
(city, farm, metro hash используют примерно то же самое)

latency умножения — 3 такта, xor и shift — 1 такт,
в одной хэш-функции нет instruction level parallelism,
поэтому всего latency примерно 12 тактов.
</section>

<section class="slide">
<h2>1. Murmur finalizer</h2>

Достоинства:
— хорошее качество;
— независимое вычисление нескольких хэшей векторизуется
  (gcc, clang даже сами это делают);
— instruction-parallel независимое вычисление нескольких хэшей;
— понятный смысл.

Недостатки:
— когда хэш-таблица помещается в L1..L2 кэш, оверхед всё-таки большой.
  (можно уменьшить до 1..1.5 раунда, если качество устраивает)
</section>

<section class="slide">
<h2>NumericHash из Arcadia</h2>

Чуть больше latency и хуже качество, чем у Murmur finalizer.
Лучше векторизуется при выполнении в цикле из-за отсутствия 64-битных умножений.
</section>

<section class="slide">
<h2>2. CRC-32C</h2>

<code>
#if __SSE4_2__

#include &lt;nmmintrin.h&gt;

inline UInt64 intHashCRC32(UInt64 x)
{
    return _mm_crc32_u64(-1ULL, x);
}

#endif
</code>
</section>

<section class="slide">
<h2>2. CRC-32C</h2>

одна инструкция
latency 3 такта
instruction level parallelism — 3 операции одновременно
throughput до 1 такта на операцию

https://software.intel.com/sites/landingpage/IntrinsicsGuide/
</section>

<section class="slide">
<h2>2. CRC-32C</h2>

Недостатки:
— всего лишь 32 бита
— нулевое качество по Avalanche и Bit Independence Criteria
  потому что crc коммутирует с xor: 
<code>  
  crc(x ^ y) = crc(x) ^ crc(y)
</code>  
  значит при изменении n-го бита x,
  m-й бит crc(x) меняется или не меняется в зависимости от n, но независимо от x.
  
  каждый бит crc — это xor некоторых бит x.

Достоинства:
— хорошо работает на практике в хэш-таблицах
</section>

<section class="slide">
Кстати, обе функции обратимы.
Но это никого не волнует.
</section>

<section class="slide">
Throughput, Latency, Avalanche
хэш-функций для int-ов:

https://github.com/yandex/ClickHouse/blob/master/dbms/src/Common/tests/int_hashes_perf.cpp
<code>./int_hashes_perf 1000000000</code>
</section>

<section class="slide">
<h2>Разрешение коллизий</h2>

Два класса хэш-таблиц...
</section>

<section class="slide">
<h2>1. Chaining</h2>
(цепочечные; с внешними явными списками разрешения коллизий)
Примеры: std::unordered_set, boost::intrusive::hash_table, Arcadia yhash.

Достоинства:
— подходит для толстых объектов;
— подходит для неперемещаемых объектов;
— подходит для intrusive контейнеров;
— node-based container, не инвалидируются указатели на ноды (внимание, итераторы инвалидируются);
— нет взаимного влияния цепочек разрешения коллизий — положительной обратной связи на разрастание цепочек;
— более терпимо к плохой хэш-функции и к большому load factor.
</section>

<section class="slide">
<h2>1. Chaining</h2>

Недостатки:
— низкая кэш-локальность;
— нагрузка на аллокатор;
— большой оверхед по памяти для маленьких значений;
</section>

<section class="slide">
<h2>2. Open-Addressing</h2>
(closed hashing; с внутренними списками разрешения коллизий)
Примеры: ClickHouse DB::HashMap, sparse_hash_map, dense_hash_map, HashMap в Rust.

Недостатки:
— очень чувствительны к выбору хэш-функции;
— например, абсолютно плохо работают с тривиальной хэш-функцией;
— многообразие вариантов memory layout и collision resolution, нужно выбирать под конкретную задачу;
— сильная деградация производительности, если хранить inplace крупные объекты;

Достоинства:
— при правильном использовании работают быстро :)
</section>

<section class="slide">
<h2>Другие варианты</h2>

Не обязательно списки.

Другие внешние явные структуры данных для разрешения коллизий:
— непрерывные массивы;
— сбалансированные деревья (пример: HashMap в Java).

Chaining с первой ячейкой inplace;
— сочетают в себе недостатки chaining и open-addressing;
— можно использовать комбинированный вариант для multiset/multimap.
</section>

<section class="slide">
<h2>Варианты memory layout для open-addressing hash table</h2>

Как обозначить, что ячейка занята?

1. Явно — бит занятости в каждой ячейке.

2. Неявно — отсутствие значение обозначено нулевым ключом,
а элемент с нулевым ключом хранится отдельно.
</section>

<section class="slide">
<h2>Варианты memory layout для open-addressing hash table</h2>

— простой массив ячеек;
— необычный массив ячеек — sparse array (пример: sparse_hash_map);
— двухуровневый массив;
— массив с address translation (косвенной адресацией);
— два массива ячеек — один для key, другой для mapped;
— два и больше массива ячеек для cuckoo hash table;
— массив ячеек + битовые маски;
</section>

<section class="slide">
<h2>Какую дополнительную информацию можно хранить в ячейках</h2>

— значение хэша — для shortcut сравнения тяжёлых ключей; для отсутствия повторных вычислений при ресайзах;
— номер версии для мгновенной очистки хэш-таблицы;
— информация, как далеко находится элемент с соответствующим значением остатка от деления хэша;
— указатели, формирующие цепочку разрешения коллизий как в chaining hash table;
— атомики для блокировок.
</section>

<section class="slide">
<h2>Способы разрешения коллизий</h2>
</section>

<section class="slide">
<h2>Во что упирается insert и lookup в хэш-таблицах?</h2>

1. В случае, когда всё влезает в L1..L2 кэш (иногда применимо для L3 кэша):
— вычисление хэш-функции;
— обход цепочек разрешения коллизий (бранчи, арифметика, иногда просто много инструкций);
— сравнение элементов на равенство.

2. В случае, когда всё не помещается в LL кэш (иногда применимо, когда влезает только в L3 кэш):
— случайные чтения из памяти.
</section>

<section class="slide">
<h2>Linear probing</h2>

Достоинства:
— отличная кэш-локальность;
— очень простой;
— самый быстрый при условии одинаковых длин цепочек;

Недостатки:
— максимально капризный метод;
— не терпит большой fill factor.

Средняя сложность lookup-а в хэш-таблице:
O(n^2), где n — средняя длина цепочки разрешения коллизий.
</section>

<section class="slide">
<h2>Quadratic probing</h2>

Достоинства:
— неплохая кэш-локальность;
— только чуть-чуть сложнее linear probing;
— слегка менее капризный;
</section>

<section class="slide">
<h2>Double hashing</h2>

Недостатки:
— плохая кэш-локальность;
— более сложный в реализации и использовании;
— менее эффективный при условии одинаковых длин цепочек;

Достоинства:
— не капризный;
</section>

<section class="slide">
<h2>Linear probing with robin hood hashing:</h2>

Недостатки:
— чуть-чуть медленнее linear probing при условии одинаковых длин цепочек;
— нужно больше вычислять или хранить значение хэш-функции для ячеек;

Достоинства:
— такая же кэш-локальность, как у linear probing;
— средние длины цепочек существенно меньше linear probing;
— хэш-таблица получается почти полностью упорядоченной по остатку от деления хэш-функции, что можно использовать в других алгоритмах.
</section>

<section class="slide">
<h2>Cuckoo hashing</h2>

Достоинства:
— O(1) lookup

Недостатки:
— два (в среднем полтора) случайных доступа к памяти вместо одного
— сложные insert-ы
</section>

<section class="slide">
<h2>Hopscotch hashing</h2>

Достоинства:
— O(1) lookup

Недостатки:
— сложные insert-ы
</section>

<section class="slide">
<h2>Еxplicit pointers chain</h2>

Недостатки:
— вообще непонятно зачем
</section>

<section class="slide">
<h2>Ресайзы</h2>

— какой max fill использовать;
— во сколько раз ресайзить;
— какой размер хэш-таблицы брать;
— как выделять и инициализировать память;
— как перемещать элементы;
</section>

<section class="slide">
<h2>Какой max fill использовать</h2>

0.5
— прекрасно подходит для самых капризных вариантов,
— если оверхед по памяти слабо волнует;
— при max fill = 0.5 и ресайзе в два раза, максимальный оверхед — 4 раза.

Больше — неприемлимо для linear probing.
Только для robin hood (не всегда) и double hashing.
</section>

<section class="slide">
<h2>Во сколько раз ресайзить</h2>

В два раза.
— это почти единственный вариант, если размер-степень двух;

Пока хэш-таблица маленькая, можно и в 4 раза.
— так как не имеет значения оверхед по памяти;
— но польза от этого маленькая;

Другие варианты:

В 1.5 раза; в golden ratio раз?
— сложно, бессмысленно, дорого;

Использовать массивы из чанков с косвенной адресацией и добавлять чанки.
— сложно, дорого.
</section>

<section class="slide">
<h2>Какой размер хэш-таблицы брать</h2>

1. 2^n
— дешёвая арифметика
— возможно чудовищное замедление при вставке элементов из одной хэш-таблицы в меньшую, если max_fill > 0.5:
https://accidentallyquadratic.tumblr.com/post/153545455987/rust-hash-iteration-reinsertion

<section class="slide">
<h2>Какой размер хэш-таблицы брать</h2>

2. Простое число, близкое к 2^n

Недостатки:
— деление с остатком — очень медленно
— если константа compile time, то компилятор заменяет на умножения и сдвиги
— чтобы было compile time, приходится использовать switch/case со всеми вариантами
— хотя бранч хорошо предсказуем, в итоге всё-равно ужасно медленно
</section>

<section class="slide">
<h2>2. Простое число, близкое к 2^n</h2>

Ложное достоинство:
— скрадывает низкое качество хэш-функции;

Почему ложное:
Повышения качества распределения элементов аналогично выбору более качественной хэш-функции,
но остаток от деления — слишком дорогой способ повышения качества.
Разумно инкапсулировать качество распределения внутри хэш-функции.

Вывод: использование простого числа — нелепость.
std::unordered_set, Arcadia yhash используют именно эту нелепость.
</section>

<section class="slide">
<h2>Как выделять и инициализировать память</h2>

Если пустая ячейка представлена нулевыми байтами, то можно использовать mmap, или calloc.
При ресайзе, можно для inplace ресайза использовать mremap или realloc.

Но:
— mmap чудовищно медленный;
— calloc почти во всех аллокаторах полностью бесполезен (работает через malloc, memset);
— realloc почти во всех аллокаторах полностью бесполезен (работает через malloc, memcpy, free);
— также заметим, что в std::allocator и вовсе нет интерфейса для realloc или calloc.
</section>

<section class="slide">
<h2>Насколько mmap медленный</h2>
~ 2000 вызовов mmap, page fault, munmap в секунду, независимо от количества ядер;

Почему mmap медленный:
— системный вызов;
— изменение структур данных в ядре;
— сброс TLB кэша;
— page fault.
</section>

<section class="slide">
<h2>Насколько mmap медленный</h2>

Можно использовать mmap, munmap, mremap только для больших кусков памяти.

64 MiB

(пусть мы умеем работать с памятью со скоростью 50 GB/sec;
 пусть мы хотим, чтобы оверхед на mmap составлял не больше половины;
 пусть mmap можно делать всего 1000 раз в секунду)
 
Вообще-то все аллокаторы уже используют mmap, если кусок памяти большой, но:
— страдают использованием mmap для недостаточно больших кусков памяти;
— не используют mremap для realloc даже в этом случае;

Поэтому использовать mmap вручную разумно.
</section>
 
<section class="slide">
<h2>Как перемещать элементы</h2>

1. Выделить новый массив, вставить туда все элементы.

Достоинства: тривиально.
</section>

<section class="slide">
<h2>Как перемещать элементы</h2>

2. Расширить массив в два раза. Правая половина будет пустой.

При условии, что размер массива всегда — степень двух, в среднем
— чуть меньше половины элементов останутся на месте;
— половина элементов переедет на новое место вправо;
— некоторая часть элементов переедет немного влево за счёт того, 
  что предыдущие в цепочке разрешения коллизий переедут в правую половину.
  
Достоинства:
— это реально эффективнее;
— меньше выделяем временной памяти;
— лучше кэш-локальность;
Недостатки:
— сложный алгоритм, легко ошибиться;


<section class="slide">
<h2>Как перемещать элементы</h2>

3. Амортизированный ресайз
— делать ресайз постепенно, размазав сложность на время вставки новых элементов.

Достоинства:
— контроль над latency;

Недостатки:
— throughput будет хуже;
— сложнее реализация;
— надо до двух случайных доступов к памяти вместо одного.
</section>

<section class="slide">
<h2>Оптимизации, которые не работают</h2>
</section>

<section class="slide">
<h2>Оптимизации, которые не работают</h2>

Ресайзить, когда цепочка стала длинной
— длина цепочки разрешения коллизий — распределение с тяжёлыми хвостами,
  и максимальная длина в случае linear probing слишком рано становится большой.
</section>
  
<section class="slide">
<h2>Оптимизации, которые не работают</h2>

Избавиться от overlap
— бессмысленно, так как в случае 2^n размера хэш-таблицы, overlap — это bit and с маской,
  и это очень простая операция, которая никак не уменьшает throughput благодаря instruction level parallelism.
</section>
  
<section class="slide">
<h2>Оптимизации, которые не работают</h2>

Вынести условие на ресайз за пределы цикла
— в данном случае хорошо предсказуемый бранч ничего не стоит
</section>

<section class="slide">
<h2>Оптимизации, которые работают</h2>

mmap, mremap для больших размеров

Inplace ресайзы
</section>

<section class="slide">
<h2>Оптимизации, которые работают</h2>
</section>

<section class="slide">
<h2>Оптимизации, которые работают</h2>

Shortcut для подряд идущих одинаковых значений ключа
</section>

<section class="slide">
<h2>Оптимизации, которые работают</h2>

Сохранение хэш-функции для тяжёлых ключей
</section>

<section class="slide">
<h2>Оптимизации, которые работают</h2>

Prefetch
</section>

<section class="slide">
<h2>Оптимизации, которые работают</h2>

Пометка методов хэш-таблицы как ALWAYS_INLINE, 
а внешних методов, содержащих циклы работы с хэш-таблицей как NO_INLINE.
</section>

<section class="slide">
<h2>Оптимизации, которые я не пробовал</h2>

предсказание размера хэш-таблицы перед её созданием

inplace хранение состояний агрегатных функций в хэш-таблице, если они маленькие

inplace хранение состояний агрегатных функций в хэш-таблице, а если они большое, то разделение на два массива — отдельно ключи и значения

хранение коротких строковых ключей inplace в хэш-таблице с разделением на несколько хэш-таблиц по power-of-two size class-ам

Unrolled speculative probing

SIMD probing
</section>

<section class="slide">
<h2>Хэш-таблицы для сложных ключей</h2>

Для строк — складываем подряд строки в Arena, в хэш-таблице храним StringRef
(std::string_view, Arcadia TStringBuf, std::pair&lt;const char *, size_t&gt;).

Для кортежей
— если кортеж маленький, то укладываем его в 64 или 128 или 256 бит и используем это в качестве ключа;
— если кортеж большой, то сериализуем его и работаем как со строковым ключом.
</section>

<section class="slide">
<h2>Это не всё.</h2>
Но у меня закончилось время.
</section>

<section class="slide">
<h2>?</h2>
</section>
    
    <div class="progress"></div>
    <script src="shower/shower.min.js"></script>
</body>
</html>
